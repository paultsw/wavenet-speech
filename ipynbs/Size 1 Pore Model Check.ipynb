{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the results of the pore model on pore-width 1. First, let's get set up by importing and switching directories to top-level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ptang/Desktop/pytorch_models/wavenet-speech\n"
     ]
    }
   ],
   "source": [
    "# switch to top-level dir:\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the essentials:\n",
    "import torch\n",
    "import numpy as np\n",
    "from modules.wavenet import WaveNet\n",
    "from modules.classifier import WaveNetClassifier\n",
    "from utils.loaders import PoreModelLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's build a pore model with the same settings as was in the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low noise and small pore width:\n",
    "num_levels = 256\n",
    "num_iterations = 100000\n",
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "epoch_size = 2500\n",
    "nt_sample_lengths = (90,110)\n",
    "pore_width = 1\n",
    "srate = 4\n",
    "noise = 1.\n",
    "nt_to_pa = { 0: 51., 1: 22., 2: 103., 3: 115. }\n",
    "dataloader = PoreModelLoader(num_iterations, num_epochs, epoch_size,\n",
    "                             batch_size=batch_size, num_levels=num_levels, lengths=nt_sample_lengths,\n",
    "                             pore_width=pore_width, sample_rate=srate, currents_dict=nt_to_pa,\n",
    "                             sample_noise=noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's instantiate a model and restore the model weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 5\n",
    "out_dim = 256\n",
    "downsample_rate = 1\n",
    "wavenet_dils = [1, 2, 3, 4,\n",
    "                1, 2, 3, 4,\n",
    "                1, 2, 3, 4]\n",
    "classifier_dils = [1, 2, 3, 4,\n",
    "                   1, 2, 3, 4,\n",
    "                   1, 2, 3, 4]\n",
    "\n",
    "wavenet = WaveNet(num_levels, 2, [(num_levels, num_levels, 2, d) for d in wavenet_dils], num_levels, softmax=False)\n",
    "classifier = WaveNetClassifier(num_levels, num_labels, [(num_levels, num_levels, 3, d) for d in classifier_dils],\n",
    "                               out_dim, pool_kernel_size=downsample_rate, input_kernel_size=2, input_dilation=1,\n",
    "                               softmax=False)\n",
    "\n",
    "# restore model weights (`map_location` moves weights from CUDA to CPU):\n",
    "wavenet.load_state_dict(torch.load(\"./runs/artificial/noiseless_porewidth_1/wavenet_model.loss0_5014.pth\",\n",
    "                                   map_location=lambda storage, loc: storage))\n",
    "classifier.load_state_dict(torch.load(\"./runs/artificial/noiseless_porewidth_1/classifier_model.loss0_5014.pth\",\n",
    "                                      map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a closured function to run the WaveNet-CTC model on inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(signal):\n",
    "    intermediate_signal = wavenet(signal)\n",
    "    transcription = classifier(intermediate_signal)\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signal, seq, seq_lengths = dataloader.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_preds = run_model(torch.autograd.Variable(signal.data, volatile=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called: G | Proba: 0.9826\n",
      "Called: G | Proba: 0.9998\n",
      "Called: G | Proba: 0.9930\n",
      "Called: C | Proba: 0.9407\n",
      "Called: C | Proba: 0.9853\n",
      "Called: T | Proba: 0.5158\n",
      "Called: T | Proba: 0.9984\n",
      "Called: T | Proba: 0.7218\n",
      "Called: C | Proba: 0.9644\n",
      "Called: C | Proba: 0.9669\n",
      "Called: C | Proba: 0.9767\n",
      "Called: C | Proba: 0.8775\n",
      "Called: A | Proba: 0.7157\n",
      "Called: A | Proba: 0.9828\n",
      "Called: A | Proba: 0.9037\n",
      "Called: G | Proba: 0.9540\n",
      "Called: G | Proba: 0.7187\n",
      "Called: A | Proba: 0.5102\n",
      "Called: A | Proba: 0.7881\n",
      "Called: A | Proba: 0.8361\n",
      "Called: A | Proba: 0.5533\n",
      "Called: G | Proba: 0.9060\n",
      "Called: G | Proba: 0.9976\n",
      "Called: G | Proba: 0.7879\n",
      "Called: T | Proba: 0.5262\n",
      "Called: T | Proba: 0.9461\n",
      "Called: A | Proba: 0.8637\n",
      "Called: G | Proba: 0.7460\n",
      "Called: G | Proba: 0.7094\n",
      "Called: G | Proba: 0.7752\n",
      "Called: G | Proba: 0.9541\n",
      "Called: C | Proba: 0.8204\n",
      "Called: C | Proba: 0.9691\n",
      "Called: A | Proba: 0.7739\n",
      "Called: A | Proba: 0.9724\n",
      "Called: A | Proba: 0.9733\n",
      "Called: A | Proba: 0.9731\n",
      "Called: A | Proba: 0.8689\n",
      "Called: T | Proba: 0.9117\n",
      "Called: T | Proba: 0.9210\n",
      "Called: T | Proba: 0.6369\n",
      "Called: T | Proba: 0.9507\n",
      "Called: G | Proba: 0.8451\n",
      "Called: G | Proba: 0.9835\n",
      "Called: G | Proba: 0.8888\n",
      "Called: C | Proba: 0.5749\n",
      "Called: C | Proba: 0.9987\n",
      "Called: C | Proba: 0.9882\n",
      "Called: C | Proba: 0.9024\n",
      "Called: T | Proba: 0.8507\n",
      "Called: G | Proba: 0.9942\n",
      "Called: G | Proba: 0.6570\n",
      "Called: C | Proba: 0.7685\n",
      "Called: C | Proba: 0.7893\n",
      "Called: A | Proba: 0.9588\n",
      "Called: A | Proba: 0.5454\n",
      "Called: T | Proba: 0.9527\n",
      "Called: T | Proba: 0.8640\n",
      "Called: A | Proba: 0.9216\n",
      "Called: A | Proba: 0.9693\n",
      "Called: G | Proba: 0.9606\n",
      "Called: G | Proba: 0.9125\n",
      "Called: C | Proba: 0.9250\n",
      "Called: C | Proba: 0.9129\n",
      "Called: G | Proba: 0.7996\n",
      "Called: G | Proba: 0.9209\n",
      "Called: G | Proba: 0.8752\n",
      "Called: A | Proba: 0.9929\n",
      "Called: A | Proba: 0.9888\n",
      "Called: A | Proba: 0.9870\n",
      "Called: G | Proba: 0.8859\n",
      "Called: G | Proba: 0.9972\n",
      "Called: G | Proba: 0.8868\n",
      "Called: T | Proba: 0.5562\n",
      "Called: T | Proba: 0.7956\n",
      "Called: A | Proba: 0.9848\n",
      "Called: A | Proba: 0.9001\n",
      "Called: A | Proba: 0.7660\n",
      "Called: T | Proba: 0.9091\n",
      "Called: T | Proba: 0.9972\n",
      "Called: T | Proba: 0.8687\n",
      "Called: G | Proba: 0.7132\n",
      "Called: G | Proba: 0.6896\n",
      "Called: G | Proba: 0.9902\n",
      "Called: G | Proba: 0.7742\n",
      "Called: T | Proba: 0.9898\n",
      "Called: A | Proba: 0.7566\n",
      "Called: A | Proba: 0.7264\n",
      "Called: C | Proba: 0.5579\n",
      "Called: C | Proba: 0.9767\n",
      "Called: C | Proba: 0.7759\n",
      "Called: A | Proba: 0.5423\n",
      "Called: A | Proba: 0.9807\n",
      "Called: A | Proba: 0.8037\n",
      "Called: A | Proba: 0.9241\n",
      "Called: A | Proba: 0.7872\n",
      "Called: T | Proba: 0.8618\n",
      "Called: T | Proba: 0.7822\n",
      "Called: C | Proba: 0.6152\n",
      "Called: C | Proba: 0.7540\n",
      "Called: C | Proba: 0.5005\n",
      "Called: A | Proba: 0.8166\n",
      "Called: A | Proba: 0.9676\n",
      "Called: A | Proba: 0.8237\n",
      "Called: G | Proba: 0.7988\n",
      "Called: G | Proba: 0.8791\n",
      "Called: C | Proba: 0.7738\n",
      "Called: C | Proba: 0.8598\n",
      "Called: T | Proba: 0.8807\n",
      "Called: T | Proba: 0.8304\n",
      "Called: T | Proba: 0.6186\n",
      "Called: G | Proba: 0.7836\n",
      "Called: G | Proba: 0.9672\n",
      "Called: G | Proba: 0.8936\n",
      "Called: G | Proba: 0.5812\n",
      "Called: G | Proba: 0.5017\n",
      "Called: T | Proba: 0.9481\n",
      "Called: T | Proba: 0.5383\n",
      "Called: C | Proba: 0.8868\n",
      "Called: C | Proba: 0.8863\n",
      "Called: C | Proba: 0.7339\n",
      "Called: G | Proba: 0.9917\n",
      "Called: G | Proba: 0.9750\n",
      "Called: G | Proba: 0.8940\n",
      "Called: A | Proba: 0.9794\n",
      "Called: A | Proba: 0.9737\n",
      "Called: A | Proba: 0.8215\n",
      "Called: G | Proba: 0.9495\n",
      "Called: G | Proba: 0.8978\n",
      "Called: C | Proba: 0.9880\n",
      "Called: C | Proba: 0.9079\n",
      "Called: T | Proba: 0.6963\n",
      "Called: G | Proba: 0.9422\n",
      "Called: G | Proba: 0.7635\n",
      "Called: G | Proba: 0.9212\n",
      "Called: C | Proba: 0.9428\n",
      "Called: C | Proba: 0.9660\n",
      "Called: C | Proba: 0.7708\n",
      "Called: C | Proba: 0.5840\n",
      "Called: C | Proba: 0.6488\n",
      "Called: G | Proba: 0.9898\n",
      "Called: G | Proba: 0.9937\n",
      "Called: G | Proba: 0.7376\n",
      "Called: T | Proba: 0.6961\n",
      "Called: T | Proba: 0.9641\n",
      "Called: T | Proba: 0.8401\n",
      "Called: A | Proba: 0.6434\n",
      "Called: A | Proba: 0.9882\n",
      "Called: A | Proba: 0.8009\n",
      "Called: A | Proba: 0.9382\n",
      "Called: A | Proba: 0.9804\n",
      "Called: C | Proba: 0.8942\n",
      "Called: C | Proba: 0.9768\n",
      "Called: T | Proba: 0.7237\n",
      "Called: T | Proba: 0.9896\n",
      "Called: T | Proba: 0.9696\n",
      "Called: C | Proba: 0.9687\n",
      "Called: C | Proba: 0.7334\n",
      "Called: G | Proba: 0.9494\n",
      "Called: G | Proba: 0.5475\n",
      "Called: G | Proba: 0.8774\n",
      "Called: G | Proba: 0.6424\n",
      "Called: T | Proba: 0.8296\n",
      "Called: T | Proba: 0.9941\n",
      "Called: T | Proba: 0.6357\n",
      "Called: T | Proba: 0.9157\n",
      "Called: C | Proba: 0.5197\n",
      "Called: C | Proba: 0.8408\n",
      "Called: C | Proba: 0.9677\n",
      "Called: A | Proba: 0.5691\n",
      "Called: A | Proba: 0.8821\n",
      "Called: A | Proba: 0.7067\n",
      "Called: A | Proba: 0.6092\n",
      "Called: C | Proba: 0.8391\n",
      "Called: C | Proba: 0.9713\n",
      "Called: C | Proba: 0.9390\n",
      "Called: T | Proba: 0.7616\n",
      "Called: T | Proba: 0.5066\n",
      "Called: T | Proba: 0.7607\n",
      "Called: T | Proba: 0.6919\n",
      "Called: A | Proba: 0.7963\n",
      "Called: A | Proba: 0.5571\n",
      "Called: G | Proba: 0.7778\n",
      "Called: G | Proba: 0.9887\n",
      "Called: G | Proba: 0.8041\n",
      "Called: T | Proba: 0.9206\n",
      "Called: T | Proba: 0.6331\n",
      "Called: C | Proba: 0.5244\n",
      "Called: C | Proba: 0.7933\n",
      "Called: C | Proba: 0.9548\n",
      "Called: C | Proba: 0.9696\n",
      "Called: C | Proba: 0.9317\n",
      "Called: A | Proba: 0.6103\n",
      "Called: C | Proba: 0.6699\n",
      "Called: C | Proba: 0.7845\n",
      "Called: T | Proba: 0.7281\n",
      "Called: T | Proba: 0.9682\n",
      "Called: T | Proba: 0.9738\n",
      "Called: G | Proba: 0.7193\n",
      "Called: G | Proba: 0.8053\n",
      "Called: G | Proba: 0.8206\n",
      "Called: G | Proba: 0.9891\n",
      "Called: T | Proba: 0.8306\n",
      "Called: T | Proba: 0.9882\n",
      "Called: T | Proba: 0.8382\n",
      "Called: T | Proba: 0.9484\n",
      "Called: T | Proba: 0.5844\n",
      "Called: A | Proba: 0.7357\n",
      "Called: A | Proba: 0.9625\n",
      "Called: A | Proba: 0.8819\n",
      "Called: G | Proba: 0.9704\n",
      "Called: G | Proba: 0.9796\n",
      "Called: T | Proba: 0.5341\n",
      "Called: T | Proba: 0.9947\n",
      "Called: T | Proba: 0.9262\n",
      "Called: G | Proba: 0.9937\n",
      "Called: G | Proba: 0.9576\n",
      "Called: C | Proba: 0.7730\n",
      "Called: C | Proba: 0.7923\n",
      "Called: C | Proba: 0.9888\n",
      "Called: C | Proba: 0.9882\n",
      "Called: C | Proba: 0.9732\n",
      "Called: T | Proba: 0.8817\n",
      "Called: T | Proba: 0.9527\n",
      "Called: G | Proba: 0.9878\n",
      "Called: G | Proba: 0.8372\n",
      "Called: A | Proba: 0.7314\n",
      "Called: A | Proba: 0.9250\n",
      "Called: A | Proba: 0.8749\n",
      "Called: T | Proba: 0.9299\n",
      "Called: T | Proba: 0.6826\n"
     ]
    }
   ],
   "source": [
    "# print outputs:\n",
    "_lookup_ = {0: '<BLANK>', 1: 'A', 2: 'G', 3: 'C', 4: 'T'}\n",
    "batch_ix = 1 # (choose which sequence of the batch you want to look at)\n",
    "print_blanks = False\n",
    "pred_labels = []\n",
    "for k in range(ctc_preds.size(2)):\n",
    "    logit, label = torch.max(torch.nn.functional.softmax(ctc_preds[batch_ix,:,k]), dim=0)\n",
    "    logit_py = float(logit.data[0])\n",
    "    label_py = _lookup_[int(label.data[0])]\n",
    "    if (not print_blanks) and (label_py == '<BLANK>'): continue\n",
    "    print(\"Called: {0} | Proba: {1:1.4f}\".format(label_py, logit_py))\n",
    "    pred_labels.append(label_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGGCCTTTCCCCAAAGGAAAAGGGTTAGGGGCCAAAAATTTTGGGCCCCTGGCCAATTAAGGCCGGGAAAGGGTTAAATTTGGGGTAACCCAAAAATTCCCAAAGGCCTTTGGGGGTTCCCGGGAAAGGCCTGGGCCCCCGGGTTTAAAAACCTTTCCGGGGTTTTCCCAAAACCCTTTTAAGGGTTCCCCCACCTTTGGGGTTTTTAAAGGTTTGGCCCCCTTGGAAATT\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCTCCAGAAGTAGCAATTGCTGCATAGCGGAGTATGGTACAATCAGCTGGTCGAGCTGGCCGTAACTCGGTTCACTTAGTCCACTGGTTAGTGCCCTGATT\n"
     ]
    }
   ],
   "source": [
    "# look up target sequence by using the sequence lengths as an index:\n",
    "def batch_index_lookup(bix, seq_lens):\n",
    "    start = torch.sum(seq_lens[0:bix])\n",
    "    stop = start+seq_lens[bix]\n",
    "    return (start,stop)\n",
    "_s0,_s1 = batch_index_lookup(batch_ix, seq_lengths)\n",
    "s0 = int(_s0.data[0])\n",
    "s1 = int(_s1.data[0])\n",
    "print(\"\".join(_lookup_[ix] for ix in list(seq[s0:s1].data + torch.ones(seq[s0:s1].size()).int())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
