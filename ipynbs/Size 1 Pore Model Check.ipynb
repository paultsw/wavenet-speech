{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the results of the pore model on pore-width 1. First, let's get set up by importing and switching directories to top-level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ptang/Desktop/pytorch_models/wavenet-speech\n"
     ]
    }
   ],
   "source": [
    "# switch to top-level dir:\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the essentials:\n",
    "import torch\n",
    "import numpy as np\n",
    "from modules.wavenet import WaveNet\n",
    "from modules.classifier import WaveNetClassifier\n",
    "from utils.pore_model import PoreModelLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's build a pore model with the same settings as was in the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Low noise and small pore width:\n",
    "num_levels = 256\n",
    "num_iterations = 100000\n",
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "epoch_size = 2500\n",
    "nt_sample_lengths = (90,110)\n",
    "pore_width = 1\n",
    "srate = 4\n",
    "noise = 1.\n",
    "nt_to_pa = { 1: 51., 2: 22., 3: 103., 4: 115. }\n",
    "dataloader = PoreModelLoader(num_iterations, num_epochs, epoch_size,\n",
    "                             batch_size=batch_size, num_levels=num_levels, lengths=nt_sample_lengths,\n",
    "                             pore_width=pore_width, sample_rate=srate, currents_dict=nt_to_pa,\n",
    "                             sample_noise=noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's instantiate a model and restore the model weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_labels = 5\n",
    "out_dim = 256\n",
    "downsample_rate = 1\n",
    "wavenet_dils = [1, 2, 3, 4,\n",
    "                1, 2, 3, 4,\n",
    "                1, 2, 3, 4]\n",
    "classifier_dils = [1, 2, 3, 4,\n",
    "                   1, 2, 3, 4,\n",
    "                   1, 2, 3, 4]\n",
    "\n",
    "wavenet = WaveNet(num_levels, 2, [(num_levels, num_levels, 2, d) for d in wavenet_dils], num_levels, softmax=False)\n",
    "classifier = WaveNetClassifier(num_levels, num_labels, [(num_levels, num_levels, 3, d) for d in classifier_dils],\n",
    "                               out_dim, pool_kernel_size=downsample_rate, input_kernel_size=2, input_dilation=1,\n",
    "                               softmax=False)\n",
    "\n",
    "# restore model weights (`map_location` moves weights from CUDA to CPU):\n",
    "wavenet.load_state_dict(torch.load(\"./runs/artificial/noiseless_porewidth_1/wavenet_model.loss0_5014.pth\",\n",
    "                                   map_location=lambda storage, loc: storage))\n",
    "classifier.load_state_dict(torch.load(\"./runs/artificial/noiseless_porewidth_1/classifier_model.loss0_5014.pth\",\n",
    "                                      map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a closured function to run the WaveNet-CTC model on inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(signal):\n",
    "    intermediate_signal = wavenet(signal)\n",
    "    transcription = classifier(intermediate_signal)\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, seq, seq_lengths = dataloader.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_preds = run_model(torch.autograd.Variable(signal.data, volatile=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First check the real output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCAGTCCATGCCTCAAACAGAATGATTCAGTCGGAGGTTCATTTATTTAATATTAGTCGACTTGTGGCATTAGGCAGTACCTCATTAGGGTGTC\n"
     ]
    }
   ],
   "source": [
    "batch_ix = 1 # (choose which sequence of the batch you want to look at)\n",
    "_lookup_ = {0: '<BLANK>', 1: 'A', 2: 'G', 3: 'C', 4: 'T'}\n",
    "# look up target sequence by using the sequence lengths as an index:\n",
    "def batch_index_lookup(bix, seq_lens):\n",
    "    start = torch.sum(seq_lens[0:bix])\n",
    "    stop = start+seq_lens[bix]\n",
    "    return (start,stop)\n",
    "_s0,_s1 = batch_index_lookup(batch_ix, seq_lengths)\n",
    "s0 = int(_s0.data[0])\n",
    "s1 = int(_s1.data[0])\n",
    "print(\"\".join(_lookup_[ix] for ix in list(seq[s0:s1].data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic ArgMax-decoded output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called: G | Proba: 0.8884\n",
      "Called: G | Proba: 0.9814\n",
      "Called: C | Proba: 0.9846\n",
      "Called: C | Proba: 0.8904\n",
      "Called: G | Proba: 0.6286\n",
      "Called: G | Proba: 0.9753\n",
      "Called: G | Proba: 0.9927\n",
      "Called: T | Proba: 0.7991\n",
      "Called: T | Proba: 0.7068\n",
      "Called: C | Proba: 0.8207\n",
      "Called: C | Proba: 0.6349\n",
      "Called: C | Proba: 0.5056\n",
      "Called: C | Proba: 0.7124\n",
      "Called: A | Proba: 0.8545\n",
      "Called: A | Proba: 0.9687\n",
      "Called: A | Proba: 0.8812\n",
      "Called: T | Proba: 0.8401\n",
      "Called: G | Proba: 0.7039\n",
      "Called: G | Proba: 0.9820\n",
      "Called: G | Proba: 0.9723\n",
      "Called: C | Proba: 0.7528\n",
      "Called: C | Proba: 0.9876\n",
      "Called: C | Proba: 0.9706\n",
      "Called: C | Proba: 0.7649\n",
      "Called: T | Proba: 0.7993\n",
      "Called: T | Proba: 0.8786\n",
      "Called: C | Proba: 0.9555\n",
      "Called: A | Proba: 0.7101\n",
      "Called: A | Proba: 0.9785\n",
      "Called: A | Proba: 0.9364\n",
      "Called: A | Proba: 0.6097\n",
      "Called: A | Proba: 0.7055\n",
      "Called: G | Proba: 0.7600\n",
      "Called: G | Proba: 0.7576\n",
      "Called: G | Proba: 0.9715\n",
      "Called: G | Proba: 0.9083\n",
      "Called: A | Proba: 0.7570\n",
      "Called: A | Proba: 0.9036\n",
      "Called: A | Proba: 0.9890\n",
      "Called: A | Proba: 0.8985\n",
      "Called: T | Proba: 0.9655\n",
      "Called: T | Proba: 0.9845\n",
      "Called: G | Proba: 0.9671\n",
      "Called: G | Proba: 0.8453\n",
      "Called: G | Proba: 0.6888\n",
      "Called: A | Proba: 0.6902\n",
      "Called: T | Proba: 0.5021\n",
      "Called: T | Proba: 0.8983\n",
      "Called: T | Proba: 0.7329\n",
      "Called: T | Proba: 0.7226\n",
      "Called: C | Proba: 0.8334\n",
      "Called: A | Proba: 0.8546\n",
      "Called: A | Proba: 0.6734\n",
      "Called: G | Proba: 0.9058\n",
      "Called: G | Proba: 0.9973\n",
      "Called: G | Proba: 0.9924\n",
      "Called: G | Proba: 0.9408\n",
      "Called: T | Proba: 0.7772\n",
      "Called: T | Proba: 0.8305\n",
      "Called: C | Proba: 0.5911\n",
      "Called: C | Proba: 0.6647\n",
      "Called: C | Proba: 0.7004\n",
      "Called: G | Proba: 0.9862\n",
      "Called: G | Proba: 0.5882\n",
      "Called: G | Proba: 0.8891\n",
      "Called: G | Proba: 0.5220\n",
      "Called: A | Proba: 0.9146\n",
      "Called: A | Proba: 0.9586\n",
      "Called: A | Proba: 0.8799\n",
      "Called: G | Proba: 0.9522\n",
      "Called: G | Proba: 0.5766\n",
      "Called: G | Proba: 0.6760\n",
      "Called: G | Proba: 0.6002\n",
      "Called: G | Proba: 0.9310\n",
      "Called: G | Proba: 0.6958\n",
      "Called: T | Proba: 0.9946\n",
      "Called: T | Proba: 0.9115\n",
      "Called: T | Proba: 0.9352\n",
      "Called: T | Proba: 0.6198\n",
      "Called: T | Proba: 0.6222\n",
      "Called: C | Proba: 0.6423\n",
      "Called: A | Proba: 0.9967\n",
      "Called: A | Proba: 0.9795\n",
      "Called: A | Proba: 0.5168\n",
      "Called: T | Proba: 0.9351\n",
      "Called: T | Proba: 0.5229\n",
      "Called: T | Proba: 0.7830\n",
      "Called: T | Proba: 0.8315\n",
      "Called: T | Proba: 0.6284\n",
      "Called: T | Proba: 0.5401\n",
      "Called: A | Proba: 0.8635\n",
      "Called: A | Proba: 0.9314\n",
      "Called: T | Proba: 0.9239\n",
      "Called: T | Proba: 0.4985\n",
      "Called: T | Proba: 0.6126\n",
      "Called: T | Proba: 0.7390\n",
      "Called: T | Proba: 0.5570\n",
      "Called: T | Proba: 0.8648\n",
      "Called: T | Proba: 0.7486\n",
      "Called: A | Proba: 0.6437\n",
      "Called: T | Proba: 0.8953\n",
      "Called: T | Proba: 0.6100\n",
      "Called: T | Proba: 0.5958\n",
      "Called: T | Proba: 0.8793\n",
      "Called: T | Proba: 0.9289\n",
      "Called: A | Proba: 0.9952\n",
      "Called: A | Proba: 0.9600\n",
      "Called: A | Proba: 0.7580\n",
      "Called: G | Proba: 0.8476\n",
      "Called: G | Proba: 0.9966\n",
      "Called: G | Proba: 0.6772\n",
      "Called: T | Proba: 0.6805\n",
      "Called: T | Proba: 0.9736\n",
      "Called: T | Proba: 0.8421\n",
      "Called: C | Proba: 0.8892\n",
      "Called: C | Proba: 0.9747\n",
      "Called: C | Proba: 0.6287\n",
      "Called: G | Proba: 0.6689\n",
      "Called: G | Proba: 0.7825\n",
      "Called: G | Proba: 0.9462\n",
      "Called: G | Proba: 0.7977\n",
      "Called: A | Proba: 0.8519\n",
      "Called: C | Proba: 0.8425\n",
      "Called: C | Proba: 0.9856\n",
      "Called: C | Proba: 0.6607\n",
      "Called: T | Proba: 0.7572\n",
      "Called: T | Proba: 0.9781\n",
      "Called: T | Proba: 0.5785\n",
      "Called: G | Proba: 0.7575\n",
      "Called: G | Proba: 0.9532\n",
      "Called: T | Proba: 0.7414\n",
      "Called: G | Proba: 0.8977\n",
      "Called: G | Proba: 0.7735\n",
      "Called: G | Proba: 0.7379\n",
      "Called: G | Proba: 0.7713\n",
      "Called: C | Proba: 0.5807\n",
      "Called: A | Proba: 0.5911\n",
      "Called: T | Proba: 0.7429\n",
      "Called: T | Proba: 0.9081\n",
      "Called: T | Proba: 0.9933\n",
      "Called: G | Proba: 0.9142\n",
      "Called: G | Proba: 0.8441\n",
      "Called: G | Proba: 0.9975\n",
      "Called: G | Proba: 0.9302\n",
      "Called: C | Proba: 0.8105\n",
      "Called: C | Proba: 0.7920\n",
      "Called: A | Proba: 0.7412\n",
      "Called: G | Proba: 0.8855\n",
      "Called: G | Proba: 0.9579\n",
      "Called: T | Proba: 0.7244\n",
      "Called: A | Proba: 0.8589\n",
      "Called: A | Proba: 0.8239\n",
      "Called: C | Proba: 0.9827\n",
      "Called: C | Proba: 0.6350\n",
      "Called: C | Proba: 0.9350\n",
      "Called: C | Proba: 0.8956\n",
      "Called: C | Proba: 0.6108\n",
      "Called: C | Proba: 0.9692\n",
      "Called: T | Proba: 0.8366\n",
      "Called: T | Proba: 0.5032\n",
      "Called: T | Proba: 0.6511\n",
      "Called: A | Proba: 0.9803\n",
      "Called: T | Proba: 0.5797\n",
      "Called: T | Proba: 0.7580\n",
      "Called: T | Proba: 0.7622\n",
      "Called: T | Proba: 0.9675\n",
      "Called: A | Proba: 0.6386\n",
      "Called: A | Proba: 0.9245\n",
      "Called: A | Proba: 0.9314\n",
      "Called: G | Proba: 0.8098\n",
      "Called: G | Proba: 0.6897\n",
      "Called: G | Proba: 0.8898\n",
      "Called: G | Proba: 0.5823\n",
      "Called: G | Proba: 0.7757\n",
      "Called: G | Proba: 0.6276\n",
      "Called: G | Proba: 0.9238\n",
      "Called: G | Proba: 0.9891\n",
      "Called: T | Proba: 0.9912\n",
      "Called: T | Proba: 0.9445\n",
      "Called: T | Proba: 0.7022\n",
      "Called: G | Proba: 0.8485\n",
      "Called: G | Proba: 0.6072\n",
      "Called: G | Proba: 0.7818\n",
      "Called: T | Proba: 0.9884\n",
      "Called: T | Proba: 0.9791\n",
      "Called: C | Proba: 0.9795\n",
      "Called: C | Proba: 0.9977\n"
     ]
    }
   ],
   "source": [
    "# print outputs:\n",
    "print_blanks = False\n",
    "pred_labels = []\n",
    "for k in range(ctc_preds.size(2)):\n",
    "    logit, label = torch.max(torch.nn.functional.softmax(ctc_preds[batch_ix,:,k]), dim=0)\n",
    "    logit_py = float(logit.data[0])\n",
    "    label_py = _lookup_[int(label.data[0])]\n",
    "    if (not print_blanks) and (label_py == '<BLANK>'): continue\n",
    "    print(\"Called: {0} | Proba: {1:1.4f}\".format(label_py, logit_py))\n",
    "    pred_labels.append(label_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGCCGGGTTCCCCAAATGGGCCCCTTCAAAAAGGGGAAAATTGGGATTTTCAAGGGGTTCCCGGGGAAAGGGGGGTTTTTCAAATTTTTTAATTTTTTTATTTTTAAAGGGTTTCCCGGGGACCCTTTGGTGGGGCATTTGGGGCCAGGTAACCCCCCTTTATTTTAAAGGGGGGGGTTTGGGTTCC\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam-search-decoded output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modules.beam import Beam\n",
    "beam_width = 5\n",
    "target_dict = { '<pad>': 0, 'a': 1, 'g': 2, 'c': 3, 't': 4, '<s>': 5, '</s>': 6 }\n",
    "beams = [Beam(beam_width, target_dict, cuda=False) for _ in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare logits by reshaping to (Seq,Batch,NDim) and appending <BOS> and <EOS> tags as new columns\n",
    "logits = ctc_preds.data.clone().permute(2,0,1)\n",
    "zero_col = torch.zeros(logits.size(0), logits.size(1), 1)\n",
    "logits = torch.cat((logits, zero_col, zero_col), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add <START> and <STOP> tags to the logits:\n",
    "ndim = logits.size(2)\n",
    "start_vec = torch.zeros(1, batch_size, ndim)\n",
    "start_vec[:,:,5] = 1.\n",
    "stop_vec = torch.zeros(1, batch_size, ndim)\n",
    "stop_vec[:,:,6] = 1.\n",
    "start_vec.size()\n",
    "logits = torch.cat([start_vec, logits, stop_vec], dim=0)\n",
    "sequence_length = logits.size(0) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through logits and accumulate (softmaxed) probabilities to the Beams:\n",
    "for k in range(logits.size(0)):\n",
    "    label_lkhd = torch.nn.functional.softmax(logits[k].view(batch_size, ndim)).data\n",
    "    label_lkhd = label_lkhd.unsqueeze(1).expand(batch_size,beam_width,ndim)\n",
    "    # update each beam:\n",
    "    for b in range(batch_size):\n",
    "        if beams[b].done: continue\n",
    "        beams[b].advance(label_lkhd[b,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### return decoded hypthesis sequences and probabilities/scores for each:                                                                                                                                                                                               \n",
    "num_best = 3 # (only return the top-3 best hypothesis sequence for each batch)                                                                                                                                                                                          \n",
    "hypotheses = {}\n",
    "probas = {}\n",
    "for b in range(batch_size):\n",
    "    # create dictionary entries for batch sequence b in `hypotheses`, `probas`:                                                                                                                                                                                         \n",
    "    hypotheses[b] = []\n",
    "    probas[b] = []\n",
    "    # get best probabilities and their associated indices in the beam:                                                                                                                                                                                                  \n",
    "    scores, Ks = beams[b].sort_best()\n",
    "    # append the scores to the list of best probabilities:                                                                                                                                                                                                              \n",
    "    probas[b] += [ scores[0:num_best] ]\n",
    "    # append the hypothesis sequences to the list of best hypotheses:                                                                                                                                                                                                   \n",
    "    beam_b_hyps = [ beams[b].get_hyp(k) for k in Ks[0:num_best] ]\n",
    "    hypotheses[b] += beam_b_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Logits:\n",
      "\n",
      "  0.0000   0.0000   0.0000  ...    0.0000   1.0000   0.0000\n",
      "  2.0418  -3.5993  -2.0254  ...   -2.6345   0.0000   0.0000\n",
      "  0.7959  -4.4375  -4.3781  ...   -4.6685   0.0000   0.0000\n",
      "           ...               â‹±              ...            \n",
      "  6.6841  -1.0067  -4.7337  ...   -0.8784   0.0000   0.0000\n",
      "  4.8830  -3.4591  -3.1115  ...   -1.3804   0.0000   0.0000\n",
      "  0.0000   0.0000   0.0000  ...    0.0000   0.0000   1.0000\n",
      "[torch.FloatTensor of size 438x7]\n",
      "\n",
      "Hypotheses, batch sequence 1\n",
      "[[5, 0, 0, 0, 0, 2, 2, 0, 0, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 4, 4, 0, 3, 3, 0, 0, 0, 3, 3, 1, 1, 1, 0, 0, 0, 4, 0, 0, 2, 2, 2, 0, 0, 3, 0, 3, 3, 3, 0, 0, 4, 4, 0, 0, 0, 3, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0, 1, 0, 0, 0, 4, 4, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 3, 0, 0, 1, 1, 0, 2, 2, 2, 2, 0, 4, 4, 0, 0, 3, 3, 3, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 4, 4, 4, 0, 4, 4, 0, 0, 0, 3, 1, 1, 1, 0, 4, 0, 0, 0, 4, 4, 4, 0, 4, 0, 4, 0, 1, 0, 1, 0, 0, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 1, 1, 1, 0, 2, 2, 2, 0, 4, 4, 4, 0, 3, 3, 3, 2, 2, 2, 2, 0, 1, 0, 0, 0, 3, 3, 3, 0, 4, 0, 0, 0, 0, 4, 4, 0, 2, 2, 0, 0, 4, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 3, 3, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 4, 0, 0, 1, 1, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0, 1, 1, 1, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 4, 4, 4, 0, 2, 2, 2, 0, 0, 4, 4, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6], [5, 0, 0, 0, 0, 2, 2, 0, 0, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 4, 4, 0, 3, 3, 0, 0, 0, 3, 3, 1, 1, 1, 0, 0, 0, 4, 0, 0, 2, 2, 2, 0, 0, 3, 0, 3, 3, 3, 0, 0, 4, 4, 0, 0, 0, 3, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0, 1, 0, 0, 0, 4, 4, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 3, 0, 0, 1, 1, 0, 2, 2, 2, 2, 0, 4, 4, 0, 0, 3, 3, 3, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 4, 4, 4, 0, 4, 4, 0, 0, 0, 3, 1, 1, 1, 0, 4, 0, 0, 0, 4, 4, 4, 0, 4, 0, 4, 0, 1, 0, 1, 0, 0, 4, 0, 0, 4, 4, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 1, 1, 1, 0, 2, 2, 2, 0, 4, 4, 4, 0, 3, 3, 3, 2, 2, 2, 2, 0, 1, 0, 0, 0, 3, 3, 3, 0, 4, 0, 0, 0, 0, 4, 4, 0, 2, 2, 0, 0, 4, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 3, 3, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 4, 0, 0, 1, 1, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0, 1, 1, 1, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 4, 4, 4, 0, 2, 2, 2, 0, 0, 4, 4, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6], [5, 0, 0, 0, 0, 2, 2, 0, 0, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 4, 4, 0, 3, 3, 0, 0, 0, 3, 3, 1, 1, 1, 0, 0, 0, 4, 0, 0, 2, 2, 2, 0, 0, 3, 0, 3, 3, 3, 0, 0, 4, 4, 0, 0, 0, 3, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0, 1, 0, 0, 0, 4, 4, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 3, 0, 0, 1, 1, 0, 2, 2, 2, 2, 0, 4, 4, 0, 0, 3, 3, 3, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 4, 4, 4, 0, 4, 4, 0, 0, 0, 3, 1, 1, 1, 0, 4, 0, 0, 0, 4, 4, 4, 0, 4, 0, 4, 0, 1, 0, 1, 0, 0, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 1, 1, 1, 0, 2, 2, 2, 0, 4, 4, 4, 0, 3, 3, 3, 2, 2, 2, 2, 0, 1, 0, 0, 0, 3, 3, 3, 0, 4, 0, 0, 0, 0, 4, 4, 0, 2, 2, 0, 0, 4, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 3, 3, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 4, 0, 0, 1, 1, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0, 1, 1, 1, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 4, 4, 4, 0, 2, 2, 2, 0, 0, 4, 4, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6]]\n",
      "Probabilities, batch sequence 1\n",
      "[\n",
      " 333.0540\n",
      " 333.0539\n",
      " 333.0530\n",
      "[torch.FloatTensor of size 3]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# print output at batch_ix:\n",
    "print(\"=\" * 80)\n",
    "print(\"Logits:\")\n",
    "print(logits[:,batch_ix,:])\n",
    "print(\"Hypotheses, batch sequence {}\".format(batch_ix))\n",
    "print(hypotheses[batch_ix])\n",
    "print(\"Probabilities, batch sequence {}\".format(batch_ix))\n",
    "print(probas[batch_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0, 0, 0, 0, 2, 2, 0, 0, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 4, 4, 0, 3, 3, 0, 0, 0, 3, 3, 1, 1, 1, 0, 0, 0, 4, 0, 0, 2, 2, 2, 0, 0, 3, 0, 3, 3, 3, 0, 0, 4, 4, 0, 0, 0, 3, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0, 1, 0, 0, 0, 4, 4, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 3, 0, 0, 1, 1, 0, 2, 2, 2, 2, 0, 4, 4, 0, 0, 3, 3, 3, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 4, 4, 4, 0, 4, 4, 0, 0, 0, 3, 1, 1, 1, 0, 4, 0, 0, 0, 4, 4, 4, 0, 4, 0, 4, 0, 1, 0, 1, 0, 0, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 1, 1, 1, 0, 2, 2, 2, 0, 4, 4, 4, 0, 3, 3, 3, 2, 2, 2, 2, 0, 1, 0, 0, 0, 3, 3, 3, 0, 4, 0, 0, 0, 0, 4, 4, 0, 2, 2, 0, 0, 4, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 3, 3, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 4, 0, 0, 1, 1, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0, 1, 1, 1, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 4, 4, 4, 0, 2, 2, 2, 0, 0, 4, 4, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6]\n"
     ]
    }
   ],
   "source": [
    "print(hypotheses[batch_ix][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCGTCCATGCCTCAAAAGAATGATTCAGTCGAGTTCATTTTAATTTATAGTCGACTTGTGGGCATTGGCAGGTACTATTAGGTGTC\n"
     ]
    }
   ],
   "source": [
    "# convert to AGCTs:\n",
    "collapsed = []\n",
    "translated = []\n",
    "for k in range(1,len(hypotheses[batch_ix][0])-1):\n",
    "    if (hypotheses[batch_ix][0][k] != hypotheses[batch_ix][0][k-1]):\n",
    "        collapsed.append(hypotheses[batch_ix][0][k])\n",
    "        if hypotheses[batch_ix][0][k] != 0: translated.append(_lookup_[hypotheses[batch_ix][0][k]])\n",
    "print(\"\".join(translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison:\n",
    "```\n",
    "Original:  GCAGTCCATGCCTCAAA-CAGAATGATTCAGTCGGAGGTTCATTT-A-TTTAATATTAGTCGACTTGTGG-CATTAGGCAG-TACCTCATTAGGGTGTC\n",
    "Predicted: GC-GTCCATGCCTCAAAAGA-A-TGATTCAGTCG-AG-TTCATTTTAATTTA-TA---GTCGACTTGTGGGCATT-GGCAGGTAC-T-ATTAGG-TGTC\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
